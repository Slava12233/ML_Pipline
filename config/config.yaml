# Unified Fine-tuning Pipeline Configuration

# Environment
environment: local  # Can be 'local', 'vertex', 'production', etc.

# Project Settings
project:
  name: fine-tuning-pipeline
  version: 0.1.0
  description: Pipeline for fine-tuning models on PDF documentation

# Google Cloud Settings
gcp:
  project_id: risk-manager-457219  # Update with your actual project ID
  region: us-central1
  zone: us-central1-a
  storage:
    bucket_name: risk-manager-agent5  # Update with your actual bucket name
    pdf_folder: pdfs
    extracted_text_folder: extracted_text
    training_data_folder: training_data
    model_folder: models

# PDF Processing Settings
pdf_processing:
  extraction_method: pypdf2  # Options: pypdf2, document_ai
  document_ai:
    processor_id: your-processor-id  # Replace with your Document AI processor ID
  chunk_size: 1000  # Maximum characters per chunk
  overlap: 200  # Character overlap between chunks
  min_chunk_length: 100  # Minimum characters for a valid chunk

# Training Data Settings
training_data:
  format: jsonl
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  examples_per_document: 10  # Target number of examples to generate per document
  min_input_length: 10
  max_input_length: 1024
  min_output_length: 20
  max_output_length: 2048

# Fine-tuning Settings
fine_tuning:
  model: gpt2  # Base model to use
  method: peft  # Options: peft, full
  peft:
    method: lora  # Options: lora, prefix_tuning, p_tuning
    r: 16  # LoRA rank
    alpha: 32  # LoRA alpha
    dropout: 0.1  # LoRA dropout
    target_modules:  # Target modules for LoRA
      - c_attn
      - c_proj
  training:
    batch_size: 8
    learning_rate: 1.0e-5
    epochs: 3
    warmup_steps: 100
    weight_decay: 0.01
    gradient_accumulation_steps: 4
    max_grad_norm: 1.0
    fp16: true
  vertex_ai:
    project_id: risk-manager-457219
    region: us-central1
    machine_type: n1-standard-8
    accelerator_type: NVIDIA_TESLA_V100
    accelerator_count: 1
    service_account: null
    container_uri: gcr.io/cloud-aiplatform/training/pytorch-gpu.1-13:latest

# Evaluation Settings
evaluation:
  metrics:
    - rouge
    - bleu
    - bertscore
  human_evaluation:
    enabled: true
    num_examples: 50
    criteria:
      - relevance
      - factuality
      - coherence
      - helpfulness

# Deployment Settings
deployment:
  endpoint_name: model-endpoint
  machine_type: n1-standard-4
  min_replicas: 1
  max_replicas: 5
  accelerator_type: null  # Options: null, NVIDIA_TESLA_T4, NVIDIA_TESLA_V100
  accelerator_count: 0
